{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLHQrcXAYdNQ"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Farhad-Davaripour/Navigating_GenAI/blob/main/function_calling/function_calling_demo.ipynb\" target=\"_parent\">\n",
        "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYG3rKwGYdNT"
      },
      "source": [
        "# Invoking an LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IHYaPZMYdNT",
        "outputId": "225cc05f-71fe-4e8b-8730-e9f34d2f7973"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Using cached openai-1.30.1-py3-none-any.whl (320 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.1\n"
          ]
        }
      ],
      "source": [
        "%pip install openai scikit-learn\n",
        "%pip install openai openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "V46EZzEhYdNU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "OPENAI_API_KEY=\"\"\n",
        "\n",
        "# Set the environment variable\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key=OPENAI_API_KEY\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6LXyQK1DYdNV"
      },
      "outputs": [],
      "source": [
        "# Generate response using the language model\n",
        "def create_prompt(prompt):\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"You are an AI assistant that provides answer to the user's query.\"\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": f\"{prompt}\"\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0k7nSeF6YdNV"
      },
      "outputs": [],
      "source": [
        "def generate_response(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",  # Replace with the appropriate model name\n",
        "        messages=create_prompt(prompt),\n",
        "        max_tokens=150\n",
        "    )\n",
        "    return response\n",
        "\n",
        "def print_response(prompt):\n",
        "    response = generate_response(prompt)\n",
        "    for key in response.choices[0]:\n",
        "        print(key)\n",
        "    print(\"\\nResponse: \", response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO_qYw-JYdNW",
        "outputId": "7ffb1541-034b-4b75-969b-6ca5640b3e55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('finish_reason', 'stop')\n",
            "('index', 0)\n",
            "('logprobs', None)\n",
            "('message', ChatCompletionMessage(content='The capital of Canada is Ottawa.', role='assistant', function_call=None, tool_calls=None))\n",
            "\n",
            "Response:  The capital of Canada is Ottawa.\n"
          ]
        }
      ],
      "source": [
        "response = print_response(\"What is the capital of Canada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRcoOnkRYdNX",
        "outputId": "389bf88c-5ec3-498c-828e-ec8d6dd67831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('finish_reason', 'length')\n",
            "('index', 0)\n",
            "('logprobs', None)\n",
            "('message', ChatCompletionMessage(content=\"Generating a scatter plot involves creating a plot where each point represents a pair of `x` and `y` values on a Cartesian coordinate system. The following Python code uses the popular plotting library Matplotlib to achieve this:\\n\\n```python\\nimport matplotlib.pyplot as plt\\n\\n# Define the data\\nx_values = [1, 2, 3, 4, 5]\\ny_values = [10, 20, 25, 30, 35]\\n\\n# Create the scatter plot\\nplt.scatter(x_values, y_values)\\n\\n# Add titles and labels\\nplt.title('Scatter Plot of X and Y Values')\\nplt.xlabel('X Values')\\nplt.ylabel('Y Values')\\n\\n# Display the plot\\nplt.show()\\n```\\n\\nTo use this\", role='assistant', function_call=None, tool_calls=None))\n",
            "\n",
            "Response:  Generating a scatter plot involves creating a plot where each point represents a pair of `x` and `y` values on a Cartesian coordinate system. The following Python code uses the popular plotting library Matplotlib to achieve this:\n",
            "\n",
            "```python\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# Define the data\n",
            "x_values = [1, 2, 3, 4, 5]\n",
            "y_values = [10, 20, 25, 30, 35]\n",
            "\n",
            "# Create the scatter plot\n",
            "plt.scatter(x_values, y_values)\n",
            "\n",
            "# Add titles and labels\n",
            "plt.title('Scatter Plot of X and Y Values')\n",
            "plt.xlabel('X Values')\n",
            "plt.ylabel('Y Values')\n",
            "\n",
            "# Display the plot\n",
            "plt.show()\n",
            "```\n",
            "\n",
            "To use this\n"
          ]
        }
      ],
      "source": [
        "x_values = [1, 2, 3, 4, 5]\n",
        "y_values = [10, 20, 25, 30, 35]\n",
        "\n",
        "response = print_response(f'generate a scatter plot with x values {x_values} and y values {y_values}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKnVxHsfYdNY"
      },
      "source": [
        "# Function Calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJv0Wn13YdNY",
        "outputId": "ab4f412d-e6b7-4ba1-894d-1f2046f401f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully installed dataclasses-json-0.6.6 jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.0 langchain-text-splitters-0.2.0 langchain_core-0.2.0 langchain_openai-0.1.7 langsmith-0.1.60 marshmallow-3.21.2 mypy-extensions-1.0.0 orjson-3.10.3 packaging-23.2 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "%pip install matplotlib langchain langchain_core langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_MKg7PrEYdNY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from langchain.agents import tool\n",
        "\n",
        "@tool\n",
        "def scatter_plot(x: list, y: list):\n",
        "    \"\"\"\n",
        "    Plot a scatter plot using two lists: x and y\n",
        "    :param x: List of x values\n",
        "    :param y: List of y values\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    if len(x) != len(y):\n",
        "        raise ValueError(\"The length of x and y must be the same\")\n",
        "\n",
        "    plt.scatter(x, y)\n",
        "    plt.xlabel('X values')\n",
        "    plt.ylabel('Y values')\n",
        "    plt.title('Scatter Plot of X vs Y')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CY_FKY71YdNZ"
      },
      "outputs": [],
      "source": [
        "tools = [scatter_plot]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ke9L4HP-YdNZ"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are an AI assistant that provides answer to the user's query.\",\n",
        "        ),\n",
        "        (\"user\", \"{input}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mnLANJHRYdNZ"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages\n",
        "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "llm = ChatOpenAI(temperature=0.1, model=\"gpt-4o\")\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "agent = (\n",
        "    {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
        "            x[\"intermediate_steps\"]\n",
        "        ),\n",
        "    }\n",
        "    | prompt\n",
        "    | llm_with_tools\n",
        "    | OpenAIToolsAgentOutputParser()\n",
        ")\n",
        "\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent, tools=tools, verbose=False, handle_parsing_errors=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "N8-Vv7IAYdNZ"
      },
      "outputs": [],
      "source": [
        "def agent_executor_fn(prompt: str) -> str:\n",
        "    return list(agent_executor.stream({\"input\": prompt}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "k3MhULj2YdNa",
        "outputId": "b0ca0f36-92d8-4636-e4d0-2f5858ab9f4b"
      },
      "outputs": [],
      "source": [
        "x_values = [1, 2, 3, 4, 5]\n",
        "y_values = [10, 20, 25, 30, 35]\n",
        "\n",
        "for key in response:\n",
        "    print(key)\n",
        "\n",
        "response = agent_executor_fn(f'plot a scatter plot with x values {x_values} and y values {y_values}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
